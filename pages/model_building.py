# æ¨¡å‹æ„å»º

import os
import pandas as pd
import numpy as np
import datetime
import matplotlib.pyplot as plt
import altair as alt
import streamlit as st
import tensorflow as tf
from tensorflow import keras
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error as MSE


def app():
    st.title('Model Building')
    st.session_state.info_st.success("åœè½¦å æœ‰ç‡é¢„æµ‹æ¨¡å‹æ„å»ºğŸ‘‰")

    # å®šä¹‰å…¨å±€å˜é‡
    data = pd.read_csv(os.path.join(st.session_state.data_output, 'timeSeriesFeatures.csv'), index_col=0)
    locations = pd.read_csv(os.path.join(st.session_state.data_output, 'locations_processed.csv'))
    if 'parking_dict' not in st.session_state:
        st.session_state.parking_dict = {}  # å­˜å‚¨æ‰€æœ‰åœè½¦åœºçš„å…³äºæ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯
    col = st.selectbox(
        'è¯·é€‰æ‹©æ¨¡å‹è®­ç»ƒçš„åœè½¦åœº:',
        data.columns
        )
    st.session_state.parking_dict[col] = {}  # æ¸…ç©ºåœè½¦åœºæ‰€æœ‰ä¿¡æ¯ï¼Œé‡æ–°è¿›è¡Œæ¨¡å‹è®­ç»ƒè¿‡ç¨‹

    st.write("---")
    st.subheader("æ•°æ®é¢„å¤„ç†")
    preprocess(data, locations, col)

    st.write("---")
    st.subheader("æ¨¡å‹è®­ç»ƒ")
    training(col, epochs=30)

    st.write("---")
    st.subheader("æ¨¡å‹è¯„ä¼°")
    evaluate()

    st.write("---")
    st.subheader("æ¨¡å‹é¢„æµ‹")


def preprocess(data, locations, col):
    train_ratio = 0.8
    SEQ_LEN = 18  # 8:00 - 16:30 çš„æ•°æ®é•¿åº¦
    batch_size = 32

    temp = st.info("åˆ’åˆ†ç‰¹å¾å’Œæ ‡ç­¾")
    X = data
    y = data.loc[:, data.columns == col]
    st.write('ç‰¹å¾ç»´åº¦(æ—¶é—´åºåˆ—é•¿åº¦, åœè½¦åœºæ•°æ®): ', X.shape)
    st.write('æ ‡ç­¾ç»´åº¦(æ—¶é—´åºåˆ—é•¿åº¦, 1): ', y.shape)
    Spatialweight = locations[col]
    st.write(col, 'åœè½¦åœºçš„ç©ºé—´æƒé‡ï¼š', pd.DataFrame(Spatialweight).T)
    X = X.mul(list(Spatialweight))
    temp.success("åˆ’åˆ†ç‰¹å¾å’Œæ ‡ç­¾")

    temp = st.info("åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")
    st.write('è®­ç»ƒé›†å æ¯”: ', train_ratio)
    Xtrain, Xtest, Ytrain, Ytest = split_dataset(X, y, train_ratio=train_ratio)
    altdata = data.reset_index()
    altdata['index'] = altdata.index
    altdata['train_valid'] = ["Train" if x <=len(Ytrain) else "Vaild" for x in altdata.index]
    line = alt.Chart(altdata).mark_line().encode(
        x='index:Q',
        y=f'{col}:Q',
        color=alt.Color('train_valid:N'),
    ).interactive()
    st.altair_chart(line, use_container_width=True)
    temp.success("åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†")

    temp = st.info("æ„é€ æ—¶é—´åºåˆ—æ•°æ®é›†å¹¶è¿›è¡Œæ‰¹å¤„ç†")
    st.write('LSTM æ»‘åŠ¨çª—å£é•¿åº¦: ', SEQ_LEN)
    st.write('æ‰¹å¤„ç†çš„batch_size: ', batch_size)
    train_dataset, train_labels = create_dataset(Xtrain, Ytrain, seq_len=SEQ_LEN)
    test_dataset, test_labels = create_dataset(Xtest, Ytest, seq_len=SEQ_LEN)
    st.write('æ—¶é—´åºåˆ—ç‰¹å¾ç»´åº¦(è®­ç»ƒé›†é•¿åº¦, æ»‘åŠ¨çª—å£é•¿åº¦, ç‰¹å¾ç»´åº¦): ', train_dataset.shape)
    st.write('æ—¶é—´åºåˆ—æ ‡ç­¾ç»´åº¦(è®­ç»ƒé›†é•¿åº¦, æ ‡ç­¾ç»´åº¦): ', train_labels.shape)
    train_batch_dataset = create_batch_dataset(train_dataset, train_labels, batch_size=batch_size)
    test_batch_dataset = create_batch_dataset(test_dataset, test_labels, train=False, batch_size=batch_size)
    st.write("æ„å»ºæ‰¹æ•°æ®çš„ç›®çš„æ˜¯åŠ é€Ÿæ¨¡å‹è®­ç»ƒã€‚")
    temp.success("æ„é€ æ—¶é—´åºåˆ—æ•°æ®é›†å¹¶è¿›è¡Œæ‰¹å¤„ç†")

    # ç¼“å­˜é¢„å¤„ç†æ•°æ®é›†
    st.session_state.parking_dict[col]['train_dataset'] = train_dataset
    st.session_state.parking_dict[col]['train_labels'] = train_labels
    st.session_state.parking_dict[col]['test_dataset'] = test_dataset
    st.session_state.parking_dict[col]['test_labels'] = test_labels
    st.session_state.parking_dict[col]['train_batch_dataset'] = train_batch_dataset
    st.session_state.parking_dict[col]['test_batch_dataset'] = test_batch_dataset

def training(col, epochs=30):
    if os.path.exists(os.path.join('./data/output/models/', col)):
        temp = st.info('æ¨¡å‹æ­£åœ¨ä»äº‘ç«¯åŠ è½½...')
        model = tf.keras.models.load_model(os.path.join('./data/output/models/', col))
        temp.success('æ¨¡å‹åŠæƒé‡å·²æˆåŠŸåŠ è½½ï¼')
    else:
        train_dataset = st.session_state.parking_dict[col]['train_dataset']
        train_batch_dataset = st.session_state.parking_dict[col]['train_batch_dataset']
        test_batch_dataset = st.session_state.parking_dict[col]['test_batch_dataset']

        temp = st.info('æ„å»º LSTM ç¥ç»ç½‘ç»œ')
        model = keras.Sequential([
            keras.layers.LSTM(128, input_shape=train_dataset.shape[-2:], return_sequences=True),
            keras.layers.Dropout(0.5),
            keras.layers.LSTM(64),
            keras.layers.Dense(1)  # å…¨è¿æ¥å±‚ï¼Œè¾“å‡ºä¸º1
        ])
        temp.info('å®šä¹‰ Tensorboard æ—¥å¿—')
        log_dir="./data/output/logs/fit/" + col + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
        temp.info('ç¼–è¯‘ã€è®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹')
        st.write('æ¨¡å‹ä¼˜åŒ–å‡½æ•°: adam')
        st.write('æ¨¡å‹æŸå¤±å‡½æ•°: mse')
        st.write('æ¨¡å‹è®­ç»ƒè½®æ¬¡: ', epochs)
        model.compile(optimizer='adam', loss="mse")
        history = model.fit(train_batch_dataset,
            epochs=epochs,
            validation_data=test_batch_dataset,
            callbacks=[tensorboard_callback],
            verbose=0)  # æ²‰é»˜è¾“å‡º
        model.save(os.path.join('./data/output/models/', col), save_format='h5')
        temp.success('æ¨¡å‹è®­ç»ƒå®Œæ¯•ï¼')
    # ç¼“å­˜æ¨¡å‹
    st.session_state.parking_dict[col]['model'] = model

def evaluate():
    import sys
    import time
    import socket
    import streamlit.components.v1 as components

    # è·å–æœ¬æœºip
    host=socket.gethostbyname(socket.gethostname())
    col1, col2 = st.columns(2)
    if col1.button('è®¿é—®TensorBoard', help='è‹¥è®¿é—®å¤±è´¥ï¼Œå°è¯•é‡æ–°è®¿é—®'):
        if 'localhost' not in st.session_state:
            # æ²¡æœ‰ç¼“å­˜ï¼Œåˆ™å¯åŠ¨å¹¶æ‰“å¼€ç«¯å£ï¼›æœ‰ç¼“å­˜ç›´æ¥æ‰“å¼€ç«¯å£ã€‚
            if sys.platform.startswith('win'):
                os.system(f'start tensorboard --logdir ./data/output/logs/fit/ --host={host} --port=6006')  # start å¼€å¯æ–°è¿›ç¨‹
            elif sys.platform.startswith('linux'):
                os.system(f'tensorboard --logdir ./data/output/logs/fit/ --host={host} --port=6006 &')  # & å¼€å¯æ–°è¿›ç¨‹
            # é˜»å¡ä¸€å®šæ—¶é—´ï¼Œç­‰å¾…ç«¯å£å¯åŠ¨
            my_bar = st.progress(0)
            for percent_complete in range(100):
                time.sleep(0.05)
                my_bar.progress(percent_complete + 1)
            # ä¸ºäº†ä¸‹æ¬¡ç›´æ¥è®¿é—®
            st.session_state.localhost = True
        components.iframe(f"http://{host}:6006/", scrolling=True, height=900)
        # åˆ©ç”¨é‡å¯æœºåˆ¶å…³é—­é¡µé¢æ˜¾ç¤ºï¼ˆå®é™…ä¸Šè¿˜èƒ½è®¿é—®åˆ°ï¼Œé™¤éé€€å‡ºstreamlitï¼‰
        if col2.button('å…³é—­TensorBoard'):
            pass

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
def split_dataset(X, y, train_ratio=0.8):
    '''åŸºäºXå’Œy, åˆ‡åˆ†ä¸ºtrainå’Œtest
    Params:
        X : ç‰¹å¾æ•°æ®é›†
        y : æ ‡ç­¾æ•°æ®é›†
        train_ratio : è®­ç»ƒé›†å Xçš„æ¯”ä¾‹
    Returns:
        X_train, X_test, y_train, y_test
    '''
    X_len = len(X) # ç‰¹å¾æ•°æ®é›†Xçš„æ ·æœ¬æ•°é‡
    train_data_len = int(X_len * train_ratio) # è®­ç»ƒé›†çš„æ ·æœ¬æ•°é‡
    X_train = X[:train_data_len] # è®­ç»ƒé›†
    y_train = y[:train_data_len] # è®­ç»ƒæ ‡ç­¾é›†
    X_test = X[train_data_len:] # æµ‹è¯•é›†
    y_test = y[train_data_len:] # æµ‹è¯•é›†æ ‡ç­¾é›†
    # è¿”å›å€¼
    return X_train, X_test, y_train, y_test

# æ„é€ æ—¶é—´åºåˆ—æ•°æ®é›†
def create_dataset(X, y, seq_len=10):
    features = []
    targets = []
    for i in range(0, len(X) - seq_len, 1):
        data = X.iloc[i:i+seq_len] # åºåˆ—æ•°æ®ï¼ˆé•¿åº¦ä¸ºseq_lençš„å‘é‡ï¼‰
        label = y.iloc[i+seq_len] # æ ‡ç­¾æ•°æ®ï¼ˆé•¿åº¦ä¸º1ï¼‰
        # ä¿å­˜åˆ°featureså’Œlabels
        features.append(data)
        targets.append(label)
    return np.array(features), np.array(targets)

# æ„é€ æ‰¹è®­ç»ƒæ•°æ®ï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒï¼ˆæ³¨æ„åŒºåˆ«è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼‰
def create_batch_dataset(X, y, train=True, buffer_size=100, batch_size=32):
    batch_data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y))) # æ•°æ®å°è£…ï¼Œtensorç±»å‹
    if train: # è®­ç»ƒé›†
        return batch_data.cache().shuffle(buffer_size).batch(batch_size)
    else: # æµ‹è¯•é›†
        return batch_data.batch(batch_size)

# ç»˜åˆ¶è¯¯å·®æ›²çº¿
def plot_predict(Ytest, Ypred):
    r2 = r2_score(Ytest, Ypred)
    rmse = np.sqrt(MSE(Ytest,Ypred))
    st.write('R2:', r2)
    st.write('RMSE:', rmse)
    fig = plt.figure(figsize=(8,4))
    plt.plot(range(len(Ytest)), Ytest, c='r', alpha=0.8, label='True')
    plt.plot(range(len(Ytest)), Ypred, c='b', label='Pred')
    plt.legend(fontsize=10)
    st.pyplot(fig)
    return r2,rmse